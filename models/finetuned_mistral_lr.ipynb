{"cells":[{"cell_type":"code","source":["\n","!pip install -q --upgrade --no-cache-dir transformers datasets accelerate bitsandbytes sentencepiece huggingface_hub\n","\n","\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling, EarlyStoppingCallback\n","from huggingface_hub import login\n","from google.colab import userdata\n","import torch\n","\n","#  Login to Hugging Face Hub\n","login(userdata.get(\"token_hf\"))\n","\n","# Load your dataset\n","from google.colab import files\n","uploaded = files.upload()\n","\n","df = pd.read_csv(next(iter(uploaded)))\n","\n","def format_instruction(row):\n","    return f\"<s>[INST] Detect the emotion in the following text. Output only the emotion name.\\n\\nText: \\\"{row['Text']}\\\"\\n\\nOutput: [/INST] {row['Sentiment'].strip()}</s>\"\n","\n","df[\"formatted\"] = df.apply(format_instruction, axis=1)\n"],"metadata":{"id":"Xo5v9u3mEMBF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","dataset = Dataset.from_pandas(df[[\"formatted\"]])\n","\n","model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","#Fix padding token\n","if tokenizer.pad_token is None:\n","    tokenizer.pad_token = tokenizer.eos_token\n","\n","def tokenize(example):\n","    return tokenizer(example[\"formatted\"], truncation=True, padding=\"max_length\", max_length=512)\n","\n","dataset = dataset.map(tokenize, batched=True)\n","dataset = dataset.train_test_split(test_size=0.1, seed=42)\n","train_data = dataset[\"train\"]\n","eval_data = dataset[\"test\"]\n"],"metadata":{"id":"1HxWuy0FbIV5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n","\n","bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_compute_dtype=torch.float16,\n",")\n","\n","model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","tokenizer = AutoTokenizer.from_pretrained(model_id)\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_id,\n","    quantization_config=bnb_config,\n","    device_map=\"auto\"\n",")\n"],"metadata":{"id":"tmIXKQ7Adeae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","\n","model = prepare_model_for_kbit_training(model)\n","\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=[\"q_proj\", \"v_proj\"],\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()\n"],"metadata":{"id":"ugFs1x_ednCn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data.set_format(\"torch\")\n","eval_data.set_format(\"torch\")\n"],"metadata":{"id":"1iMB2yvvjcbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -q trl>=0.7.4"],"metadata":{"id":"HdynMRiWe8_I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import trl\n","print(trl.__version__)\n"],"metadata":{"id":"l3lskYv8faDa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from trl import SFTTrainer, SFTConfig\n","\n","sft_config = SFTConfig(\n","    output_dir=\"./mistral-lora-emotion\",\n","    num_train_epochs=8,\n","    per_device_train_batch_size=1,\n","    per_device_eval_batch_size=1,\n","    gradient_accumulation_steps=4,\n","    eval_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    save_total_limit=2,\n","    logging_steps=10,\n","    load_best_model_at_end=True,\n","    learning_rate=2e-5,\n","    warmup_ratio=0.1,\n","    lr_scheduler_type=\"linear\",\n","    max_seq_length=512,\n","    fp16=True,\n","    report_to=[],\n",")\n"],"metadata":{"id":"1Zwmp8Fxe__F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer = SFTTrainer(\n","    model=model,\n","    args=sft_config,\n","    train_dataset=train_data,\n","    eval_dataset=eval_data,\n","    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",")\n","#Start training\n","trainer.train()"],"metadata":{"id":"ekm0MWSDdrwm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"07lp9qwn2v84"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model_path = \"/content/drive/MyDrive/mistral-lora-emotion\"\n","model.save_pretrained(model_path)\n","tokenizer.save_pretrained(model_path)\n"],"metadata":{"id":"PjSMoDkgdtva"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n","from peft import PeftModel\n","import torch\n","\n","base_model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n","lora_model_path = \"/content/drive/MyDrive/mistral-lora-emotion\"\n","offload_dir = \"/content/offload\"\n"],"metadata":{"id":"NyedQISMpFaF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","os.makedirs(offload_dir, exist_ok=True)\n","\n","# Load base model\n","tokenizer = AutoTokenizer.from_pretrained(base_model_id)\n","\n","base_model = AutoModelForCausalLM.from_pretrained(\n","    base_model_id,\n","    torch_dtype=torch.float16,\n","    device_map=\"auto\",\n","    offload_folder=offload_dir\n",")\n"],"metadata":{"id":"SgTKG0mopH7f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Load LoRA adapter\n","model = PeftModel.from_pretrained(\n","    base_model,\n","    lora_model_path,\n","    device_map=\"auto\",\n","    offload_folder=offload_dir\n",")\n","\n","# Wrap in pipeline\n","pipe = pipeline(\n","    \"text-generation\",\n","    model=model,\n","    tokenizer=tokenizer,\n","    device_map=\"auto\"\n",")"],"metadata":{"id":"U2XYuZZ0pLFf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function for emotion detection\n","def detect_emotion(user_text):\n","    prompt = f'<s>[INST] Detect the emotion in the following text. Output only the emotion name.\\n\\nText: \"{user_text}\"\\n\\nOutput: [/INST]'\n","    output = pipe(prompt, max_new_tokens=10, do_sample=False)[0]['generated_text']\n","    response = output.split(\"[/INST]\")[-1].strip().split(\"</s>\")[0].strip()\n","    return response\n","\n","\n","user_input = input(\"Enter a sentence to detect the emotion: \")\n","emotion = detect_emotion(user_input)\n","print(f\"\\nDetected Emotion: {emotion}\")\n"],"metadata":{"id":"RLivyAGa1-xf"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyPXOuIiAkVMr+OAiB7KOmqy"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}