{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install dependencies\n",
        "# !pip install -U numpy==1.24.4\n",
        "!pip install numpy\n",
        "!pip install -U torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -U transformers datasets==2.14.6 emoji==1.7.0 scikit-learn matplotlib seaborn\n"
      ],
      "metadata": {
        "id": "RyhqY6_9_qGs",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "W0tyvyXvg_Gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "-8HEKujqhHOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Upload CSV file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "uutqGxeXBAAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Load Dataset\n",
        "import pandas as pd\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_csv(filename)\n"
      ],
      "metadata": {
        "id": "sbsEiIHkCd67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert 'Text' in df.columns and 'Sentiment' in df.columns, \"Your CSV must contain 'Text' and 'Sentiment' columns.\"\n",
        "\n",
        "# STEP 5: Encode Sentiment labels to integers\n",
        "label2id = {label: idx for idx, label in enumerate(sorted(df['Sentiment'].unique()))}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "df['label'] = df['Sentiment'].map(label2id)"
      ],
      "metadata": {
        "id": "uEk8_h83Ci51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Train/Test Split\n",
        "from datasets import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "train_ds = Dataset.from_pandas(train_df[['Text', 'label']])\n",
        "test_ds = Dataset.from_pandas(test_df[['Text', 'label']])\n"
      ],
      "metadata": {
        "id": "Sr_Nm_7RClro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "id": "nvbawqaEiruG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 7: Load tokenizer and model\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "model_name = \"vinai/bertweet-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=len(label2id), id2label=id2label, label2id=label2id)"
      ],
      "metadata": {
        "id": "yNz5hZ1qhdMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Tokenize\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"Text\"], truncation=True, padding=True)\n",
        "\n",
        "train_ds = train_ds.map(tokenize, batched=True)\n",
        "test_ds = test_ds.map(tokenize, batched=True)\n"
      ],
      "metadata": {
        "id": "HBTB3lHIhgCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: Data Collator\n",
        "from transformers import DataCollatorWithPadding\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "Zcg7fAP4hiLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 10: Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"no\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    load_best_model_at_end=False,\n",
        ")"
      ],
      "metadata": {
        "id": "3kDzJHa2hkHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 11: Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n"
      ],
      "metadata": {
        "id": "UoPGWK2nhnCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 12: Train Model\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "vpn5IJePhpBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 13: Evaluate\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "preds = trainer.predict(test_ds)\n",
        "y_true = preds.label_ids\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "\n",
        "\n",
        "unique_labels_in_test = np.unique(y_true)\n",
        "\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "\n",
        "print(classification_report(y_true, y_pred,\n",
        "                            labels=unique_labels_in_test,\n",
        "                            target_names=[id2label[i] for i in unique_labels_in_test]))"
      ],
      "metadata": {
        "id": "xoD0fd_whq-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 14: Confusion Matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", xticklabels=id2label.values(), yticklabels=id2label.values(), cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Z2GGytgKhtDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 15: Custom Input Prediction\n",
        "def predict_emotion(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "        pred_label = torch.argmax(probs, dim=1).item()\n",
        "    return id2label[pred_label]\n"
      ],
      "metadata": {
        "id": "4c6Y4TL9hu6H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxG4nkD_9miX"
      },
      "outputs": [],
      "source": [
        "# Example: Test with custom input\n",
        "custom_text = input(\"Enter a text for sentiment analysis: \")\n",
        "predicted_emotion = predict_emotion(custom_text)\n",
        "print(f\"\\nCustom Input: {custom_text}\")\n",
        "print(f\"Predicted Sentiment: {predicted_emotion}\")\n"
      ]
    }
  ]
}